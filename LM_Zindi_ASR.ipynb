{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LM_Zindi_ASR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "586f49008f154f0c9700491a9aee9ef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2922410be3b9498282bc611f6f2e349d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ddab7e1c1e7542be977cec77fe963253",
              "IPY_MODEL_aa558c7ab09846418de55faa937002a6"
            ]
          }
        },
        "2922410be3b9498282bc611f6f2e349d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ddab7e1c1e7542be977cec77fe963253": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e86f705a5617461eac4398bcbd14d559",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 460,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 460,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b4872eb4c67f4961815a6b3d63f280d3"
          }
        },
        "aa558c7ab09846418de55faa937002a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6f5ef9c99c6448eb943831ebd44ce6f9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 460/460 [00:01&lt;00:00, 417B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_deeb0858aab54116b854a3e1fc78837d"
          }
        },
        "e86f705a5617461eac4398bcbd14d559": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b4872eb4c67f4961815a6b3d63f280d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f5ef9c99c6448eb943831ebd44ce6f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "deeb0858aab54116b854a3e1fc78837d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b5be59c30eb41e792e82450596684ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6220f2dc0b87463fa372e9f872ac93c3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b9a2cc047b4b4a829aa4005f6e44d8c9",
              "IPY_MODEL_013a4a0aa056413391aed07d52f50882"
            ]
          }
        },
        "6220f2dc0b87463fa372e9f872ac93c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b9a2cc047b4b4a829aa4005f6e44d8c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1ff56c48a0754bb29ff69daf910aa491",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 378,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 378,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c87180841aeb488d8e2a30bced90b5c7"
          }
        },
        "013a4a0aa056413391aed07d52f50882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d07a2de7c31f47d4bafe77397b497e67",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 378/378 [00:00&lt;00:00, 589B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5091fad2282545808ce79df072b4af4d"
          }
        },
        "1ff56c48a0754bb29ff69daf910aa491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c87180841aeb488d8e2a30bced90b5c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d07a2de7c31f47d4bafe77397b497e67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5091fad2282545808ce79df072b4af4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0fa98473436e4763bc71a30f63e9ce5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fb980d556d6647b6a8e9188841a2a02b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7d1b3d28baf749a59ee8948ed9258773",
              "IPY_MODEL_407b6752374643218cd78baffe08a784"
            ]
          }
        },
        "fb980d556d6647b6a8e9188841a2a02b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d1b3d28baf749a59ee8948ed9258773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fd633b140dc444a1ab4da3c3869a5b52",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 85,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 85,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f423dd749cc44295b3c1378b96f6fd9e"
          }
        },
        "407b6752374643218cd78baffe08a784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d8e13cbdf028481fb371e0a3bb56136b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 85.0/85.0 [00:01&lt;00:00, 84.1B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a410ab62e85467fbb0eef81d95b97bf"
          }
        },
        "fd633b140dc444a1ab4da3c3869a5b52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f423dd749cc44295b3c1378b96f6fd9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d8e13cbdf028481fb371e0a3bb56136b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a410ab62e85467fbb0eef81d95b97bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1dd2a5c9113f49c886c408a65a5f75a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6f054fae88d84fb2a5d30cb05602fef4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b82285acbbd84e719f2a034fb01e6438",
              "IPY_MODEL_e9c5a5f9a88d4a9c9f80179903ad9ee9"
            ]
          }
        },
        "6f054fae88d84fb2a5d30cb05602fef4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b82285acbbd84e719f2a034fb01e6438": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4d8ccae39af84ae9ba50f482964ee573",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1947,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1947,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1b70d70797764e118a540e8c35d5c728"
          }
        },
        "e9c5a5f9a88d4a9c9f80179903ad9ee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7c3508d1e16241329f53952855a64e88",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4.55k/? [00:00&lt;00:00, 17.6kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cd3009c8e172460198d0771b0d03f6b8"
          }
        },
        "4d8ccae39af84ae9ba50f482964ee573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1b70d70797764e118a540e8c35d5c728": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7c3508d1e16241329f53952855a64e88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cd3009c8e172460198d0771b0d03f6b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Tw0Lqm5073z"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CktwOwj01mM"
      },
      "source": [
        "## path\n",
        "path = 'drive/MyDrive/Colab Notebooks/'\n",
        "save_name = 'predictionsLM_02MayLMvocab.csv' # name for saved predictions\n",
        "model_name = 'wav2vec2-large-xlsr-french-13Apr/checkpoint-260/'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAO8Kt4_1WlF"
      },
      "source": [
        "%%capture\n",
        "!pip install datasets # to use\n",
        "!pip install git+https://github.com/huggingface/transformers # to user huggingface transformer\n",
        "!pip install jiwer # for wer metric\n",
        "\n",
        "!pip install -U pip\n",
        "!pip install -U dill\n",
        "!pip install -U nltk==3.4"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7iUidpl1aZ6"
      },
      "source": [
        "## load packages\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import os.path\n",
        "\n",
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2CTCTokenizer\n",
        "from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2Processor\n",
        "\n",
        "from datasets import load_metric\n",
        "\n",
        "import librosa as lb\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from nltk.util import pad_sequence\n",
        "from nltk.util import ngrams, bigrams\n",
        "from nltk.lm.preprocessing import pad_both_ends, padded_everygram_pipeline\n",
        "from nltk.lm.preprocessing import flatten\n",
        "\n",
        "from nltk.lm import MLE\n",
        "\n",
        "# removing special characters\n",
        "import re\n",
        "\n",
        "# for nearest neighbor\n",
        "import difflib"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNqhX5Jf1lFh"
      },
      "source": [
        "# seeding\n",
        "random.seed(10)\n",
        "np.random.seed(10)\n",
        "torch.manual_seed(10)\n",
        "torch.cuda.manual_seed_all(10)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoQppKuT1nst",
        "outputId": "fa0b73e0-363c-40af-d0f8-645fbb676fcb"
      },
      "source": [
        "## mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVB9MG970-Zx"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MILC_uop1nCg"
      },
      "source": [
        "## read into memory (small)\n",
        "df = pd.read_feather('drive/MyDrive/Colab Notebooks/data/ASR_train_audio6683.ft')\n",
        "\n",
        "## train valid split\n",
        "df_train, df_valid = train_test_split(df, test_size=0.2, random_state=1234)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9ev0iGy1AyJ"
      },
      "source": [
        "### XLSR Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QC7SJwHPPaTC"
      },
      "source": [
        "## word corpus for nearest neighbor\n",
        "from nltk.probability import FreqDist\n",
        "from wordcloud import WordCloud, ImageColorGenerator\n",
        "\n",
        "#\n",
        "words = df_train['transcription']\n",
        "allwords = []\n",
        "\n",
        "for wordlist in words:\n",
        "  allwords += list(wordlist.lower().split())\n",
        "\n",
        "# histogram\n",
        "mostcommon_small = FreqDist(allwords).most_common(1500) # it has around 1000 distinct words -> 1500 to be sure that all are included\n",
        "xv, yv = zip(*mostcommon_small)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264,
          "referenced_widgets": [
            "586f49008f154f0c9700491a9aee9ef7",
            "2922410be3b9498282bc611f6f2e349d",
            "ddab7e1c1e7542be977cec77fe963253",
            "aa558c7ab09846418de55faa937002a6",
            "e86f705a5617461eac4398bcbd14d559",
            "b4872eb4c67f4961815a6b3d63f280d3",
            "6f5ef9c99c6448eb943831ebd44ce6f9",
            "deeb0858aab54116b854a3e1fc78837d",
            "4b5be59c30eb41e792e82450596684ac",
            "6220f2dc0b87463fa372e9f872ac93c3",
            "b9a2cc047b4b4a829aa4005f6e44d8c9",
            "013a4a0aa056413391aed07d52f50882",
            "1ff56c48a0754bb29ff69daf910aa491",
            "c87180841aeb488d8e2a30bced90b5c7",
            "d07a2de7c31f47d4bafe77397b497e67",
            "5091fad2282545808ce79df072b4af4d",
            "0fa98473436e4763bc71a30f63e9ce5c",
            "fb980d556d6647b6a8e9188841a2a02b",
            "7d1b3d28baf749a59ee8948ed9258773",
            "407b6752374643218cd78baffe08a784",
            "fd633b140dc444a1ab4da3c3869a5b52",
            "f423dd749cc44295b3c1378b96f6fd9e",
            "d8e13cbdf028481fb371e0a3bb56136b",
            "3a410ab62e85467fbb0eef81d95b97bf",
            "1dd2a5c9113f49c886c408a65a5f75a5",
            "6f054fae88d84fb2a5d30cb05602fef4",
            "b82285acbbd84e719f2a034fb01e6438",
            "e9c5a5f9a88d4a9c9f80179903ad9ee9",
            "4d8ccae39af84ae9ba50f482964ee573",
            "1b70d70797764e118a540e8c35d5c728",
            "7c3508d1e16241329f53952855a64e88",
            "cd3009c8e172460198d0771b0d03f6b8"
          ]
        },
        "id": "mQOfoGgp1ByH",
        "outputId": "9d2d3788-2b7a-43f6-d1e5-7254476477ac"
      },
      "source": [
        "## Re-evaluate performance of model\n",
        "# load XLSR model\n",
        "if not 'XLSRmodel' in globals():\n",
        "  print('Load model')\n",
        "  XLSRmodel = Wav2Vec2ForCTC.from_pretrained('./drive/MyDrive/Colab Notebooks/model/'+str(model_name)).to(\"cuda\")\n",
        "\n",
        "# load processor\n",
        "if not 'processor' in globals():\n",
        "  print('Load processor')\n",
        "  tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(\"facebook/wav2vec2-large-xlsr-53-french\")\n",
        "  feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)\n",
        "  processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)\n",
        "\n",
        "# prepare dataset\n",
        "def prepare_dataset(batch):\n",
        "    return processor(batch, return_tensors=\"pt\", sampling_rate=16*1e3)\n",
        "\n",
        "# word error rate\n",
        "wer_metric = load_metric(\"wer\")\n",
        "wer_ = []\n",
        "\n",
        "# model prediction\n",
        "model_valid = []\n",
        "# model + vocab prediction\n",
        "model_vocab_valid = []\n",
        "\n",
        "#\n",
        "input_dict = df_valid['audio_signal'].apply(prepare_dataset)\n",
        "\n",
        "## WER over everything (one long string)\n",
        "label_str = ''\n",
        "pred_str = ''\n",
        "\n",
        "for idx in range(len(df_valid)):\n",
        "  #print('-----------------')\n",
        "  logits = XLSRmodel(input_dict.values[idx].input_values.to(\"cuda\")).logits\n",
        "  pred_ids = torch.argmax(logits, dim=-1)[0]\n",
        "\n",
        "  ## WER over everything (one long string)\n",
        "  pred_str+= processor.decode(pred_ids)+ ' '\n",
        "  label_str+= df_valid[\"transcription\"].values[idx].lower()+ ' '\n",
        "\n",
        "wer_.append(wer_metric.compute(predictions=[pred_str], references=[label_str]))\n",
        "\n",
        "print(np.mean(wer_))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load model\n",
            "Load processor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "586f49008f154f0c9700491a9aee9ef7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=460.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b5be59c30eb41e792e82450596684ac",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=378.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0fa98473436e4763bc71a30f63e9ce5c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=85.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1dd2a5c9113f49c886c408a65a5f75a5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1947.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "0.14248886805718303\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgboLRG43Hpp"
      },
      "source": [
        "### Beam Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oh7Hwn5g3AEx"
      },
      "source": [
        "# Beam Search\n",
        "# https://towardsdatascience.com/boosting-your-sequence-generation-performance-with-beam-search-language-model-decoding-74ee64de435a\n",
        "\n",
        "import math\n",
        "\n",
        "def beam_search_decoder(predictions, top_k = 3):\n",
        "    #start with an empty sequence with zero score\n",
        "    output_sequences = [([], 0)]\n",
        "    \n",
        "    #looping through all the predictions\n",
        "    for token_probs in predictions:\n",
        "        new_sequences = []\n",
        "        \n",
        "        #append new tokens to old sequences and re-score\n",
        "        for old_seq, old_score in output_sequences:\n",
        "            for char_index in range(len(token_probs)):\n",
        "                new_seq = old_seq + [char_index]\n",
        "                #considering log-likelihood for scoring\n",
        "                new_score = old_score + math.log(token_probs[char_index])\n",
        "                new_sequences.append((new_seq, new_score))\n",
        "                \n",
        "        #sort all new sequences in the de-creasing order of their score\n",
        "        output_sequences = sorted(new_sequences, key = lambda val: val[1], reverse = True)\n",
        "        \n",
        "        #select top-k based on score \n",
        "        # *Note- best sequence is with the highest score\n",
        "        output_sequences = output_sequences[:top_k]\n",
        "        \n",
        "    return output_sequences"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80Mhxc6wpAW-",
        "outputId": "84b040c1-5dcb-4ba5-b082-92353e71ad3b"
      },
      "source": [
        "# test beam search \n",
        "idx = 10\n",
        "nbeams = 10\n",
        "softmax = nn.Softmax(dim=2)\n",
        "\n",
        "#\n",
        "pred = []\n",
        "input_dict = df_train['audio_signal'][idx:idx+1].apply(prepare_dataset)\n",
        "\n",
        "for idx in range(len(input_dict)):\n",
        "  #print('-----------------')\n",
        "  logits = XLSRmodel(input_dict.values[idx].input_values.to(\"cuda\")).logits\n",
        "  # sum_j(output_ij) = 1 where i is column and j is row\n",
        "  output = softmax(logits) # logits -> probabilities\n",
        "\n",
        "  beams_int = beam_search_decoder(torch.squeeze(output).tolist(), top_k = nbeams) # beams\n",
        "  beams_str = nbeams*['']\n",
        "\n",
        "  for k in range(nbeams):\n",
        "    pred_ids, pred_prob = beams_int[k]\n",
        "    print(processor.decode(pred_ids))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "marché yeumbeul laa bëgg dem\n",
            "marché yeumbeul laa bëgg dem\n",
            "marché yeumbeul laa bëgg dem\n",
            "marché yeumbeul laa bëgg dem\n",
            "marché yeumbeul laa bëgg dem\n",
            "marché yeumbeul laa bëgg dem\n",
            "marché yeumbeul laa bëgg dem\n",
            "marché yeumbeul laa bëgg dem\n",
            "marché yeumbeul laa bëgg dem\n",
            "marché yeumbeul laa bëgg dem\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3F24ZyA3LQ9"
      },
      "source": [
        "### Word Level Language Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ2OOznq3AC7"
      },
      "source": [
        "## Language Model (n-gram vs KenLM)\n",
        "# https://surfertas.github.io/deeplearning/pytorch/2017/08/20/n-gram.html # pytorch code (NN parametrization of LM)\n",
        "# https://web.stanford.edu/~jurafsky/slp3/slides/LM_4.pdf\n",
        "# https://www.kaggle.com/alvations/n-gram-language-model-with-nltk # code taken from here\n",
        "# https://web.stanford.edu/~jurafsky/slp3/old_oct19/3.pdf -> improvements to LM's"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhXsAzIWQ6S-"
      },
      "source": [
        "# fitting of language model\n",
        "def train_ngram(LMmodel, data):\n",
        "  '''\n",
        "  input: model, list of sentences\n",
        "  output: trained model\n",
        "  '''\n",
        "  #\n",
        "  sentence_list = [sentence for sentence in data]\n",
        "\n",
        "  # lower casing\n",
        "  word_list_lower = [[re.sub('[,()\"]', '', word.lower()) for word in sentence.split(' ')] for sentence in sentence_list]\n",
        "\n",
        "  # preprocess for language model\n",
        "  train_data, padded_words = padded_everygram_pipeline(3, word_list_lower)\n",
        "  \n",
        "  # fit model\n",
        "  LMmodel.fit(train_data, padded_words)\n",
        "\n",
        "  return LMmodel"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LonoDd17ThkN"
      },
      "source": [
        "## language model\n",
        "LMmodel = MLE(3) # Lets train a n-gram model\n",
        "LMmodel = train_ngram(LMmodel, df_train['transcription'].values)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4x8hRidS_nG"
      },
      "source": [
        "# WORD LEVEL LANGUAGE MODEL ################################################\n",
        "def ngram_logprobability(sentence):\n",
        "    log_prob = 0\n",
        "    count = 0\n",
        "    for ngram in sentence:\n",
        "      # to avoid log(0) for unknown chars => many methods exist in the literature such as smoothing\n",
        "      # since log is monotonically increasing, adding a const should not change the ordering, right?\n",
        "      log_prob += np.log(LMmodel.score(ngram[2], [ngram[0], ngram[1]])+ 1e-8)\n",
        "      count += 1\n",
        "    return np.power(np.exp(log_prob), 1/count) # (inverse) perplexity to account for different word/ sentence length"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72-oKWPoTESq"
      },
      "source": [
        "## Probability of sentence\n",
        "def prob_sentences(sentences):\n",
        "  '''\n",
        "  input: list of sentences\n",
        "  output: log probability for sentences\n",
        "  '''\n",
        "\n",
        "  # list with log probabilities\n",
        "  log_probs = len(sentences)* [-np.infty]\n",
        "\n",
        "  # creating list of sentences from string\n",
        "  list_sentences = [sentence.split(' ') for sentence in sentences]\n",
        "\n",
        "  # lower casing\n",
        "  for k in range(len(list_sentences)):\n",
        "    list_sentences[k] = [word.lower() for word in list_sentences[k]]\n",
        "\n",
        "  # list(sentence_list(word_list(ngrams)))\n",
        "  list_ngrams = [list(ngrams(pad_both_ends(sentence, n=3), n=3)) for sentence in list_sentences]\n",
        "\n",
        "  for k, sentence in enumerate(list_ngrams):\n",
        "    log_probs[k] = ngram_logprobability(sentence)\n",
        "\n",
        "  return log_probs"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEDJRXzaQ7L3"
      },
      "source": [
        "### Character Level Language Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD79x0G12__v"
      },
      "source": [
        "## fitting of language model\n",
        "def train_ngram(LMmodel, data):\n",
        "  '''\n",
        "  input: model, list of sentences\n",
        "  output: trained model\n",
        "  '''\n",
        "\n",
        "  # one long string of words\n",
        "  word_string = ' '.join(data)\n",
        "\n",
        "  # one long list of words\n",
        "  word_list = word_string.split(' ')\n",
        "\n",
        "  # lower casing\n",
        "  word_list_lower = [list(map(str.lower, [word]))[0]\n",
        "                     for word in word_list]\n",
        "\n",
        "  # preprocess for language model\n",
        "  train_data, padded_words = padded_everygram_pipeline(2, word_list_lower)\n",
        "  \n",
        "  # fit model\n",
        "  LMmodel.fit(train_data, padded_words)\n",
        "\n",
        "  return LMmodel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "YI3YS3j72_9O",
        "outputId": "75cc9dbd-44fd-4ae4-a7a1-9b7ca18cca7b"
      },
      "source": [
        "## language model\n",
        "# IMPORTANT there seems to be a missmatch in the vocabulary (44 vs 49 chars)\n",
        "# -> could lead to language model not knowing the character\n",
        "LMmodel = MLE(3) # Lets train a n-gram model\n",
        "LMmodel = train_ngram(LMmodel, df_train['transcription'].values)\n",
        "print(LMmodel.vocab)\n",
        "print(len(tokenizer.get_vocab()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Vocabulary with cutoff=1 unk_label='<UNK>' and 776 items>\n",
            "49\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nprint(LMmodel.counts['c'])\\nprint(LMmodel.counts[['c']]['o'])  # P('o'|'c')\\nprint(LMmodel.score('o', ['c']))\\nprint(LMmodel.vocab.lookup([char for char in test_lower[5]]))\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r06wXfQlqmEV",
        "outputId": "995e24c1-645e-4a20-f4de-3d6e71999fcd"
      },
      "source": [
        "# voabulary of language model (extracted from data)\n",
        "print([ch for ch in LMmodel.vocab])\n",
        "print(\"VERY STRANGE THAT THERE IS A c-cedi IN THE VOCABULARY EXTRACTED FROM THE TRAIN DATASET\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<s>', 'rufsac', '</s>', 'pharmacie', 'talibou', 'dabo', 'avenue', 'faidherbe', 'cité', 'mére', 'thérésa', 'gare', 'de', 'thiaroye', 'rue', 'baffa', 'séne', 'double', 'less', 'grande', 'mosquée', 'derkle', 'thokho', 'tournalou', 'yeumbeul', 'marché', 'laa', 'bëgg', 'dem', 'sonadis', 'rufisque', 'sococim', 'depot', 'layousse', 'faouzy', 'grand', 'dakar', 'fann', 'hock', 'canada', 'taly', 'bu', 'makk', 'pont', 'colobane', 'garage', 'camion', 'vidange', 'hopital', 'jean', 'la', 'fontaine', 'mariste', 'lamine', 'gueye', 'croisement', 'keur', 'massar', 'essence', 'touré', 'comico', 'darou', 'salam', 'parc', 'forestier', 'hann', 'massalikoul', 'jinan', 'ecobank', 'des', 'far', 'dama', 'mame', 'sira', 'ban', 'oto', 'mooy', 'jaar', 'yoff', 'yarakh', 'malicka', 'champ', 'course', 'pikine', 'seydina', 'limamoulaye', 'edk', 'oil', 'ali', 'baba', 'rond', 'point', 'mbao', 'diaxay', 'lycée', 'thierno', 'seydou', 'nourou', 'tall', 'petit', 'extension', 'bountou', 'ecole', 'les', 'pédagogues', 'police', 'parcelles', 'assainies', 'car', 'bank', 'of', 'africa', 'nan', 'laay', 'def', 'ngir', 'boulangerie', 'jaune', 'mamelles', 'tivaoune', 'peulh', 'fadia', 'orabank', 'sagef', 'elimanel', 'fall', 'thiakhogne', 'mermoz', 'dékh', 'fleuve', 'diacksao', 'terrain', 'nation', 'unies', 'zone', 'b', 'hlm', 'ndiaréme', 'thiossane', 'dieupeul', 'elhadji', 'mansour', 'sy', 'bus', 'danguou', 'lpa', 'asecna', 'ouakam', 'ferroviaire', 'station', 'shell', 'cambérène', 'port', 'sandiniery', 'echangeur', 'routiére', 'beaux', 'maraichiers', 'elton', 'ouest', 'foire', 'clinique', 'du', 'cap', 'manuel', 'gendarmerie', 'diall', \"m'baye\", 'camp', 'sékou', 'mballo', 'terminus', 'frigo', 'niary', 'tally', 'stade', 'seffa', 'ada', 'seck', 'centre', 'electrique', 'kounoune', 'tigo', 'almadies', 'embarcadére', 'gorée', 'sipres', 'al', 'azhar', 'sips', 'cimetiere', 'bétoir', 'niaye', 'khar', 'yalla', 'p', 'a', 'i', 'cimetiére', 'musulmane', 'route', 'hydrocarbures', 'lobat', 'mairie', 'lycee', 'blaise', 'diagne', 'nave', 'poste', 'courant', 'xarit', 'couture', 'sicap', 'baobab', 'niague', 'amadou', 'barry', 'bousso', 'dramé', 'notaire', 'total', 'médina', 'gounass', 'ba', 'bou', 'bess', 'cfao', 'motors', 'senegal', 'diaxxay', 'eaux', 'diockoul', 'just', 'for', 'u', 'sud', 'passage', 'icotaf', 'boulevard', 'gueule', 'tapée', 'hance', 'bernard', 'sde', 'axa', 'assurance', 'place', \"l'independance\", 'gouy', 'gui', 'diakayy', 'sonatel', 'zac', 'ics', 'béss', 'transfusion', 'sanguine', 'central', 'zinc', 'soboa', 'avion', 'cheikh', 'ahmadou', 'bamba', 'mbacke', 'souvenir', 'africain', 'feu', 'rouge', 'brioche', 'dorée', 'diamalaye', 'ville', 'sedami', 'nord', 'serigne', \"m'backé\", 'maternité', 'ndiarème', 'limamou', 'laye', 'tacko', 'ngor', 'cite', 'groupe', 'honda', 'ndaw', 'rts', 'las', 'palmas', 'le', 'baol', 'cyrnos', 'zoologique', 'rail', 'bi', 'fass', 'guediawaye', 'cem', 'joseph', 'felix', 'corréa', 'camberéne', \"d'akor\", 'assemblée', 'dieu', 'baobabs-', 'temple', 'nations', 'elementaire', 'iba', 'tali', 'bargny', 'khourounar', 'usine', 'méche', 'darling', 'dalal', 'diam', 'nganladou', 'diouf', 'mbeubeuss', 'diallo', 'tournal', 'assane', 'capec', 'niakoul', 'rap', 'nandos', 'baye', 'niasse', 'abass', 'ndao', 'benn', 'barack', 'menuserie', 'ebéniste', 'lamp', 'diop', 'nationale', 'dioutiba', 'sacré', 'coeur', 'elisabeth', 'l’indépendance', 'castor', 'bel', '-', 'air', 'routière', 'pompier', 'oilibya', 'peytavin', 'douane', 'golf', 'océan', 'guédiawaye', 'eric', 'kayser', 'front', 'terre', 'dior', 'radio', 'futurs', 'media', 'rfm', 'coisement', 'cimetière', 'universite', 'hampate', 'supdeco', 'campus', 'e', 'mbedou', 'académia', 'sapeur', \"l'obelisque\", 'ndunkou', 'mbaye', 'yengoulene', 'castors', 'anta', 'marie', 'sarr', 'arret', 'patte', \"d'oie\", 'boune', 'tapé', 'alassane', 'djigo', 'alioune', 'sow', 'thioub', 'biagui', 'chambre', 'commerce', 'orca', 'escoa', 'pompiers', 'universitaire', 'soumbédioune', 'collège', 'cœur', 'mamadou', 'kakatar', 'par', 'dupont', 'et', 'demba', 'bceao', 'samu', 'municipale', 'grand-yoff', 'basket', 'principal', 'technopole', 'marchée', 'tandem', 'immobilier', 'scat', 'urbam', 'bissap', 'routiere', 'case', 'philipe', 'maguiléne', 'senghor', '', 'x', 'virage', 'lac', 'rose', 'ndiaye', 'enseignent', 'doudou', 'basse', 'agence', 'immo', 'mbengue', 'sovonel', 'sandaga', 'roi', 'baudouin', 'ponty', 'djily', 'baobabs', 'medina', 'etoile', 'albert', 'sarraut', 'nu', 'may', 'assemblee', 'palais', 'presidentiel', 'femme', 'auto', 'santhiaba', 'pressafrik', 'cafétéria', 'creations', 'yavuz', 'sélim', 'bosphore', \"l'emergence\", 'mbédou', 'lébous', 'mbénguéne', 'carrapide', 'dépot', 'dikk', 'sapeurs', 'bachir', 'saint', 'pierre', 'fks', 'farine', 'western', 'union', 'cinéma', 'pasteur', 'dial', 'bass', 'dalifort', 'bd', 'général', 'gaule', 'centenaire', 'mouride', 'el', 'hadji', 'ibrahima', 'pénitence', 'daroukhane', 'bonnet', 'autoroute', 'seydina-limamoulaye', 'diarra', 'marechal', 'ndox', 'yaye', 'allées', 'cheikhna', 'sidaty', 'aîdara', 'penitence', 'justice', 'tableau', 'ferrailes', 'théâtre', 'national', 'malika', 'mangazin', 'jardin', 'botanique', 'primaire', 'bén', 'camberene', 'niass', 'malick', 'ancien', 'lgi', 'bem', 'aeroport', 'ministère', 'santé', 'prévention', 'aéroport', 'buiscuterie', 'kappa', 'galandou', 'supermarché', 'machallah', 'maristes', 'mar', 'enseignant', 'daral', 'ndax', 'mën', 'naa', 'jël', 'zola', 'cours', 'sainte', 'wade', 'martyr', \"l'ouganda\", 'derklé', 'penitance', 'emg', 'automobile', 'téne', 'parfumerie', 'gandour', 'village', 'art', 'sahm', 'poisson', 'biches', 'guigon', 'saveurs', \"d'asie\", 'sherif', 'ouseynou', 'thiaw', 'orange', 'face', 'contenaire', 'district', 'sanitaire', 'est', 'sauvegarde', 'hôpital', 'cto', 'feroviére', 'issa', 'cambéréne', 'scolaire', 'gaston', 'berger', 'grands', 'moulins', 'université', 'virtuel', 'sénégal', 'sultan', 'prefecture', 'lo', 'bira', 'complexe', 'xelcom', 'bache', 'ly-mo-dac', 'casino', 'vert', 'senelec', 'fan', 'jële', 'sedima', 'restaurant', 'venisia', 'parcelle', 'marchande', 'saf', 'bar', 'batrain', 'fi', 'sportiff', 'pamecas', 'cms', 'clando', 'daniel', 'sorano', 'hospitalier', 'aristide', 'dantec', 'difoncé', 'militaire', 'comercial', 'plateau', 'dialoré', 'plage', 'liberté', 'socio', 'culturel', 'wakhinane', 'nimzatt', 'claudel', \"d'epuration\", 'douta', 'baraka', 'oncf', 'demeure', 'caesar', 'stadium', 'marius', 'notre', 'dame', 'fastef', 'commissariat', 'dieuppeul', 'vdn', 'péage', 'mbenguéne', 'guinaw', 'rails', 'kennedy', 'kaki', 'institution', 'immaculée', 'conception', 'karack', 'ndiakhirate', 'sandicat', 'nabil', 'choucair', 'imprimerie', 'tandjan', 'sgbs', 'hotel', 'terrou', 'canal', 'dagoudane', 'ndoyéne', 'lébou', 'béthio', 'acapes', 'mbor', 'rouidate', 'thiane', 'ngogne', 'birane', 'ly', 'cosmetique', 'fallou', 'papa', 'guèye', 'tiléne', 'texaco', 'petersen', 'sodida', 'ndeureuhlou', 'club', 'ministre', 'khonkh', 'clean', 'fahd', 'ben', 'abdel', 'aziz', 'normale', 'supérieure', 'ningala', 'adji', 'niagna', 'dispensaire', 'norade', 'diamaguéne', 'maurice', 'delafosse', 'dominique', 'ministere', \"l'interieur\", 'senegalais', 'youssou', 'mbargane', 'ravin', 'sica', 'thiakhane', 'lat', 'flag', 'diarri', 'poul', 'medine', 'lazzare', 'privée', 'petits', 'génies', 'christa', 'talli', 'mourade', 'mbacké', 'mamelle', 'jet', \"d'eau\", 'awa', 'sante', 'gaspar', 'camara', 'cices', 'magic', 'land', \"l'obélisque\", 'saldia', 'mosquee', 'mbeur', 'abiya', 'kenedy', 'fu', 'mu', 'jëm', 'abebe', 'bikila', 'sengor', 'sofrac', 'pour', 'rokhaya', 'attijari', 'izdihar', 'bourguiba', 'poind', 'africatel', 'avs', 'diaakay', 'fouta', 'hôtel', 'diouma', 'leclerc', 'sotiba', 'hyacinthe', 'thiandoum', 'safco', 'caserne', 'samba', 'diéri', 'français', 'intersection', 'raby', 'equipe', 'plus', 'sur', 'mer', 'nioul', 'cge', '<UNK>']\n",
            "VERY STRANGE THAT THERE IS A c-cedi IN THE VOCABULARY EXTRACTED FROM THE TRAIN DATASET\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1_X0PHppglm",
        "outputId": "806a24da-d34c-4638-cc51-a1d89e071847"
      },
      "source": [
        "# vocabulary used by tokenizer (french alphabet)\n",
        "vocab_dict = {v for k, v in enumerate(tokenizer.get_vocab())}\n",
        "vocab_tokenizer = [v.lower() for v in vocab_dict]\n",
        "print(vocab_tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['m', \"'\", 'ë', 'r', 'v', 'ô', 'k', '<pad>', 'l', 'æ', 's', 'e', 'û', 'u', 'f', 'c', 'o', 'a', 'i', 'b', 'ù', 'â', 'ç', 'œ', 'w', 'd', 'ü', 'n', 'y', 't', 'î', 'q', '-', 'é', 'ï', 'è', 'j', '</s>', 'à', 'h', 'p', 'ê', '<s>', 'ÿ', 'g', 'z', 'x', '|', '<unk>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJIQfTGZ2_6w"
      },
      "source": [
        "## Perplexity\n",
        "def ngram_logprobability(sentence):\n",
        "    log_prob = 0\n",
        "    count = 0\n",
        "    for words in sentence:\n",
        "      for ngram in words:\n",
        "        # to avoid log(0) for unknown chars => many methods exist in the literature such as smoothing\n",
        "        # since log is monotonically increasing, adding a const should not change the ordering, right?\n",
        "        log_prob += np.log(LMmodel.score(ngram[1], [ngram[0]])+ 1e-8)\n",
        "        count += 1\n",
        "    return np.power(np.exp(log_prob), 1/count) # (inverse) perplexity to account for different word/ sentence length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_tgrLoB2_31"
      },
      "source": [
        "## Probability of sentence\n",
        "def prob_sentences(sentences):\n",
        "  '''\n",
        "  input: list of sentences\n",
        "  output: log probability for sentences\n",
        "  '''\n",
        "  # list with log probabilities\n",
        "  log_probs = len(sentences)* [-np.infty]\n",
        "\n",
        "  # creating list of sentences from string\n",
        "  list_sentences = [sentence.split(' ') for sentence in sentences]\n",
        "\n",
        "  # lower casing\n",
        "  for k in range(len(list_sentences)):\n",
        "    list_sentences[k] = [list(map(str.lower, [sent]))[0]\n",
        "                        for sent in list_sentences[k]]\n",
        "\n",
        "  # list(sentence_list(word_list(ngrams)))\n",
        "  list_ngrams = [[list(ngrams(pad_both_ends(word, n=2), n=2)) for word in sentence] for sentence in list_sentences]\n",
        "\n",
        "  for k, sentence in enumerate(list_ngrams):\n",
        "    log_probs[k] = ngram_logprobability(sentence)\n",
        "\n",
        "  return log_probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzW0gVN_TIjq"
      },
      "source": [
        "### Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81zQn2aG1EVU",
        "outputId": "0b4736c9-49c8-43b0-a199-f7952f72f625"
      },
      "source": [
        "#\n",
        "from operator import itemgetter\n",
        "\n",
        "## Predictions\n",
        "nbeams = 5 # this should scale roughly linearly to runtime -> with 10 runs for about 10 mins\n",
        "\n",
        "# pre-processing of data\n",
        "input_dict = df_valid['audio_signal'].apply(prepare_dataset)\n",
        "\n",
        "# word error rate\n",
        "wer_ = []\n",
        "\n",
        "#\n",
        "softmax = nn.Softmax(dim=2)\n",
        "\n",
        "# strings to calculate wer\n",
        "label_str = ''\n",
        "pred_str = ''\n",
        "\n",
        "for idx in range(len(df_valid)):\n",
        "  #print('-----------------')\n",
        "  logits = XLSRmodel(input_dict.values[idx].input_values.to(\"cuda\")).logits\n",
        "  # sum_j(output_ij) = 1 where i is column and j is row\n",
        "  output = softmax(logits) # logits -> probabilities\n",
        "\n",
        "  # beam search\n",
        "  beams_int = beam_search_decoder(torch.squeeze(output).tolist(), top_k = nbeams) # beams\n",
        "  beams_str = nbeams*['']\n",
        "\n",
        "  for k in range(nbeams):\n",
        "    pred_ids, pred_prob = beams_int[k]\n",
        "    beams_str[k] = processor.decode(pred_ids)\n",
        "\n",
        "  # nearest neighbor\n",
        "  pred = []\n",
        "  for k, word in enumerate(beams_str[np.argmax(prob_sentences(beams_str))].split(' ')):\n",
        "    sim = difflib.get_close_matches(word, xv, n=3, cutoff=0.8)\n",
        "\n",
        "    if sim == []:\n",
        "      sim = word\n",
        "    else:\n",
        "      sim = sim[0]\n",
        "\n",
        "    pred.append(sim)\n",
        "\n",
        "  # append prediction\n",
        "  pred_str+= ' '.join(pred)+ ' '\n",
        "  label_str+= df_valid[\"transcription\"].values[idx].lower()+ ' '\n",
        "\n",
        "# calculate wer\n",
        "wer_.append(wer_metric.compute(predictions=[pred_str], references=[label_str]))\n",
        "\n",
        "print(np.mean(wer_))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.08319662526365128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j6e3XwuSyhj"
      },
      "source": [
        "# with word 3-gram\n",
        "N=3 -> 0.07475978439184439\n",
        "N=5 -> 0.07030700726505741\n",
        "N=10 -> 0.06304194984766816\n",
        "N=50 -> 0.05319896883056011 => 0.118 = 11.8% auf test satz\n",
        "\n",
        "# with word 2-gram\n",
        "N=3 -> 0.07499414108272791\n",
        "N=5 -> 0.07077572064682447\n",
        "N=10 -> 0.06397937661120225\n",
        "N=20 -> 0.059057886102648234\n",
        "\n",
        "# with word 1-gram\n",
        "N=3 -> 0.07710335130067963\n",
        "N=5 -> 0.07499414108272791\n",
        "N=10 -> 0.07382235762831028"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkcHVqNAm6Fp"
      },
      "source": [
        "# with char 5-gram\n",
        "N=3 -> 0.07780642137333021\n",
        "N=5 -> 0.07569721115537849 down\n",
        "N=10 ->0.07405671431919382 down\n",
        "\n",
        "# with char 4-gram\n",
        "N=3 -> 0.07921256151863136\n",
        "N=5 -> 0.0787438481368643 down\n",
        "N=10 ->0.07850949144598078 down\n",
        "\n",
        "# with char 3-gram\n",
        "N=1 -> 0.0824935551910007\n",
        "N=2 -> 0.08202484180923365 down\n",
        "N=3 -> 0.08366533864541832 up\n",
        "N=5 -> 0.08577454886337005 up\n",
        "N=80 ->0.14811342863838764 up\n",
        "\n",
        "# with char 2-gram\n",
        "N=3 -> 0.08600890555425357\n",
        "N=5 -> 0.09210217951722521 up\n",
        "\n",
        "# w/o\n",
        "    -> 0.0824935551910007"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtWwOM_31G1E"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cAyWHup1IGk"
      },
      "source": [
        "## prediction\n",
        "# load data (dataframe) -> empty entries\n",
        "df_test = pd.read_feather('drive/MyDrive/Colab Notebooks/data/ASR_test_audio1564.ft')\n",
        "df_test = df_test[['ID', 'audio_signal']]\n",
        "df_test.head()\n",
        "\n",
        "def prepare_dataset(batch):\n",
        "    return processor(batch, return_tensors=\"pt\", sampling_rate=16*1e3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4tNbrEyNLnJ",
        "outputId": "b831dbd9-818a-4ac9-c4b5-2c63e6e0028f"
      },
      "source": [
        "# run through pre-processor\n",
        "input_dict = df_test['audio_signal'].apply(prepare_dataset)\n",
        "\n",
        "# to store predictions\n",
        "preds = []\n",
        "\n",
        "# beams\n",
        "nbeams = 80\n",
        "\n",
        "#\n",
        "softmax = nn.Softmax(dim=2)\n",
        "\n",
        "# run through model and decoder\n",
        "for i in range(len(df_test)):\n",
        "  logits = XLSRmodel(input_dict.values[i].input_values.to('cuda')).logits\n",
        "  output = softmax(logits) # logits -> probabilities\n",
        "  \n",
        "  # beam search\n",
        "  beams_int = beam_search_decoder(torch.squeeze(output).tolist(), top_k = nbeams) # beams\n",
        "  beams_str = nbeams*['']\n",
        "\n",
        "  for k in range(nbeams):\n",
        "    pred_ids, pred_prob = beams_int[k]\n",
        "    beams_str[k] = processor.decode(pred_ids)\n",
        "\n",
        "  # prediction\n",
        "  logprob = prob_sentences(beams_str)\n",
        "  pred_str = beams_str[np.argmax(logprob)]\n",
        "\n",
        "  # nearest neighbor\n",
        "  pred = []\n",
        "  for word in pred_str.split(' '):\n",
        "    sim = difflib.get_close_matches(word, xv, n=1)\n",
        "\n",
        "    if sim == []:\n",
        "      sim = word\n",
        "    else:\n",
        "      sim = sim[0]\n",
        "\n",
        "    pred.append(sim)\n",
        "\n",
        "  # append to prediction\n",
        "  preds.append(' '.join(pred))\n",
        "\n",
        "  if i % 200 == 0:\n",
        "    print('Sentence '+ str(i))\n",
        "\n",
        "# save as csv\n",
        "dfpred = pd.DataFrame(list(zip(list(df_test['ID'].values), preds)), columns=['ID', 'transcription'])\n",
        "dfpred.to_csv('./drive/MyDrive/Colab Notebooks/'+str(save_name), index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence 0\n",
            "Sentence 200\n",
            "Sentence 400\n",
            "Sentence 600\n",
            "Sentence 800\n",
            "Sentence 1000\n",
            "Sentence 1200\n",
            "Sentence 1400\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}