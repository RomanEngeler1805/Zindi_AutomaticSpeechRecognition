{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LM_Zindi_ASR.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyO+QZFkUA5iQXEO4kC6T1dm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a65eb6ddda9f4b66a101d3b341606c74":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_21e2f60293eb4b66b03a3c7a61757575","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_98619a1f5a784504ac5827692aa41cb6","IPY_MODEL_703d8d60859541e1ab2cfbcc0081b725"]}},"21e2f60293eb4b66b03a3c7a61757575":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"98619a1f5a784504ac5827692aa41cb6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_96239b013dc1400387d65e433703c781","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":460,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":460,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6937a974a8b44f86b1528df626c3bec4"}},"703d8d60859541e1ab2cfbcc0081b725":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3554ec1b6ffb4e4883ac47132a25a6d3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 460/460 [00:05&lt;00:00, 88.8B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_428658692b134c188f9c46754415dd02"}},"96239b013dc1400387d65e433703c781":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6937a974a8b44f86b1528df626c3bec4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3554ec1b6ffb4e4883ac47132a25a6d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"428658692b134c188f9c46754415dd02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b9401e00cde1488183b45fb2d4a97421":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_417bae8f1d2d4539b978e9213aa14828","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d2504aae51424a2da3f92d1a80d8fd67","IPY_MODEL_80bb5ebaf4a84c9a9c82f8f9cc8a7ae6"]}},"417bae8f1d2d4539b978e9213aa14828":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d2504aae51424a2da3f92d1a80d8fd67":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_33e644bdb18349d489ad91fed98ec31c","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":378,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":378,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f3ed636a26b0487d8e3ec3d504cf8930"}},"80bb5ebaf4a84c9a9c82f8f9cc8a7ae6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6be8ec25eff9426ea5efa8f66bc089bf","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 378/378 [00:00&lt;00:00, 451B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7bc1948556c54bd9877bd19df3c42de0"}},"33e644bdb18349d489ad91fed98ec31c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f3ed636a26b0487d8e3ec3d504cf8930":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6be8ec25eff9426ea5efa8f66bc089bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7bc1948556c54bd9877bd19df3c42de0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a3fd91ca54644b558b8f8eaf6e383775":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_98a8fa27a4584ab1bcb7ffd397c83306","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_eaeaccbb7d054d7597da1caafa96dc28","IPY_MODEL_0c3a22962bef4bbf8b371ee39ce143bd"]}},"98a8fa27a4584ab1bcb7ffd397c83306":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eaeaccbb7d054d7597da1caafa96dc28":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0aa4340426484012a63f9d8529a17c2c","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":85,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":85,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2145d9e743e44b57b4545632fa4cb3ab"}},"0c3a22962bef4bbf8b371ee39ce143bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_25cd8bdf3d3e4a26be08b5d2edfc7dd4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 85.0/85.0 [00:03&lt;00:00, 22.5B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4696c64d93724f27bfe30613d6b73d16"}},"0aa4340426484012a63f9d8529a17c2c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2145d9e743e44b57b4545632fa4cb3ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"25cd8bdf3d3e4a26be08b5d2edfc7dd4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4696c64d93724f27bfe30613d6b73d16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aac6a57a0d7145ec9304dfbf180eeb27":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_add72d89c34546dca095d87e392d45e2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2d0b7c80a208489ebc44def1e00b86be","IPY_MODEL_43eaa4c72419400fa8edd21e2ba61953"]}},"add72d89c34546dca095d87e392d45e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2d0b7c80a208489ebc44def1e00b86be":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f2971f1535364672b1dfb6119c408e6b","_dom_classes":[],"description":"Downloading: ","_model_name":"FloatProgressModel","bar_style":"success","max":1947,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1947,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f5e56e41edf44f79910cbd2dfb64acc6"}},"43eaa4c72419400fa8edd21e2ba61953":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6df90d4c42314c74bc3691f4e558d870","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4.55k/? [00:00&lt;00:00, 19.3kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_48444f89dc8d4a9784e847e9a9be42c6"}},"f2971f1535364672b1dfb6119c408e6b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f5e56e41edf44f79910cbd2dfb64acc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6df90d4c42314c74bc3691f4e558d870":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"48444f89dc8d4a9784e847e9a9be42c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"6Tw0Lqm5073z"},"source":["### Setup"]},{"cell_type":"code","metadata":{"id":"_CktwOwj01mM","executionInfo":{"status":"ok","timestamp":1621808353652,"user_tz":-120,"elapsed":782,"user":{"displayName":"Roman Engeler","photoUrl":"","userId":"01825020783678319162"}}},"source":["## path\n","path = 'drive/MyDrive/Colab Notebooks/'\n","save_name = 'predictionsLM_24MayXModelsLM.csv' # name for saved predictions\n","model_name = 'wav2vec2-large-xlsr-french-22May/checkpoint-4680'#"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"AAO8Kt4_1WlF","executionInfo":{"status":"ok","timestamp":1621808396851,"user_tz":-120,"elapsed":41872,"user":{"displayName":"Roman Engeler","photoUrl":"","userId":"01825020783678319162"}}},"source":["%%capture\n","!pip install datasets # to use\n","!pip install git+https://github.com/huggingface/transformers # to user huggingface transformer\n","!pip install jiwer # for wer metric\n","\n","!pip install -U pip\n","!pip install -U dill\n","!pip install -U nltk==3.4"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"l7iUidpl1aZ6","executionInfo":{"status":"ok","timestamp":1621808404041,"user_tz":-120,"elapsed":48882,"user":{"displayName":"Roman Engeler","photoUrl":"","userId":"01825020783678319162"}}},"source":["## load packages\n","# standard python\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import random\n","import os.path\n","import math\n","from operator import itemgetter\n","\n","# preprocessing\n","import librosa as lb\n","import re\n","from datasets import load_metric\n","from sklearn.model_selection import train_test_split\n","from scipy.stats import entropy\n","\n","# torch\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# transformers\n","from transformers import Wav2Vec2ForCTC, Wav2Vec2CTCTokenizer\n","from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2Processor\n","\n","# language model\n","from nltk.util import pad_sequence\n","from nltk.util import ngrams, bigrams\n","from nltk.lm.preprocessing import pad_both_ends, padded_everygram_pipeline\n","from nltk.lm.preprocessing import flatten\n","from nltk.lm import MLE, KneserNeyInterpolated\n","\n","# nearest neighbor\n","import difflib"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"gNqhX5Jf1lFh","executionInfo":{"status":"ok","timestamp":1621808404042,"user_tz":-120,"elapsed":46541,"user":{"displayName":"Roman Engeler","photoUrl":"","userId":"01825020783678319162"}}},"source":["## seeding\n","random.seed(10)\n","np.random.seed(10)\n","torch.manual_seed(10)\n","torch.cuda.manual_seed_all(10)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DoQppKuT1nst","executionInfo":{"status":"ok","timestamp":1621808422652,"user_tz":-120,"elapsed":64995,"user":{"displayName":"Roman Engeler","photoUrl":"","userId":"01825020783678319162"}},"outputId":"881954db-2221-4b02-ec78-3b969abc716a"},"source":["## mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UVB9MG970-Zx"},"source":["### Data"]},{"cell_type":"code","metadata":{"id":"MILC_uop1nCg","executionInfo":{"status":"ok","timestamp":1621808432304,"user_tz":-120,"elapsed":9645,"user":{"displayName":"Roman Engeler","photoUrl":"","userId":"01825020783678319162"}}},"source":["## read into memory (small)\n","df = pd.read_feather('drive/MyDrive/Colab Notebooks/data/ASR_train_audio6683.ft')\n","\n","# train valid split\n","df_train, df_valid = train_test_split(df, test_size=0.2, random_state=1234)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tC2xKrSS3Fzl","executionInfo":{"status":"ok","timestamp":1621808432702,"user_tz":-120,"elapsed":10035,"user":{"displayName":"Roman Engeler","photoUrl":"","userId":"01825020783678319162"}},"outputId":"f78b4454-56f7-4d78-aaa5-056d11c58754"},"source":["## French data set\n","dfFrench = pd.read_csv('drive/MyDrive/Colab Notebooks/data/ASR_French/fn_text.txt', delimiter=\"wav \")[:6298]\n","dfFrench.columns = [\"ID\", \"transcription\"]\n","audio_signals = len(dfFrench)*[[0]]\n","dfFrench['audio_signal'] = audio_signals"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n","  \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"hxKJ6ZQg3F4M","executionInfo":{"status":"ok","timestamp":1621808433872,"user_tz":-120,"elapsed":11198,"user":{"displayName":"Roman Engeler","photoUrl":"","userId":"01825020783678319162"}}},"source":["## Wolof data set\n","dfWolof = pd.read_csv('drive/MyDrive/Colab Notebooks/data/ASR_Wolof/train/text', names=[\"mixed\"])\n","dfWolof[[\"ID\", \"transcription\"]] = dfWolof[\"mixed\"].str.split(' ', 1, expand=True)\n","dfWolof = dfWolof.drop([\"mixed\"], axis=1)\n","audio_signals = len(dfWolof)*[[0]]\n","dfWolof['audio_signal'] = audio_signals"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aJ0hxFml3O2V","executionInfo":{"status":"ok","timestamp":1621808438944,"user_tz":-120,"elapsed":685,"user":{"displayName":"Roman Engeler","photoUrl":"","userId":"01825020783678319162"}},"outputId":"6740e3c8-69b5-41f2-f785-2e47eb418c1e"},"source":["## Concatenate data sets\n","df_train = df[['ID', 'transcription', 'audio_signal']]\n","df_train = pd.concat([df_train, dfFrench, dfWolof])\n","print(len(df_train))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["26979\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"M9ev0iGy1AyJ"},"source":["### XLSR Model"]},{"cell_type":"code","metadata":{"id":"QC7SJwHPPaTC","executionInfo":{"status":"ok","timestamp":1621808445606,"user_tz":-120,"elapsed":692,"user":{"displayName":"Roman Engeler","photoUrl":"","userId":"01825020783678319162"}}},"source":["## word corpus for nearest neighbor\n","from nltk.probability import FreqDist\n","from wordcloud import WordCloud, ImageColorGenerator\n","\n","## Zindi dataset\n","words = filter(None, [re.sub('[,().?!~;1234567890^]', '', word.lower()) for word in list(df['transcription'].values)])\n","allwords = []\n","\n","for wordlist in words:\n","  allwords += list(wordlist.lower().split())\n","\n","# histogram. time & space complexity linear in data set size\n","mostcommon_small = FreqDist(allwords).most_common(1500) # it has around 1000 distinct words -> 1500 to be sure that all are included\n","xvZ, yvZ = zip(*mostcommon_small)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281,"referenced_widgets":["a65eb6ddda9f4b66a101d3b341606c74","21e2f60293eb4b66b03a3c7a61757575","98619a1f5a784504ac5827692aa41cb6","703d8d60859541e1ab2cfbcc0081b725","96239b013dc1400387d65e433703c781","6937a974a8b44f86b1528df626c3bec4","3554ec1b6ffb4e4883ac47132a25a6d3","428658692b134c188f9c46754415dd02","b9401e00cde1488183b45fb2d4a97421","417bae8f1d2d4539b978e9213aa14828","d2504aae51424a2da3f92d1a80d8fd67","80bb5ebaf4a84c9a9c82f8f9cc8a7ae6","33e644bdb18349d489ad91fed98ec31c","f3ed636a26b0487d8e3ec3d504cf8930","6be8ec25eff9426ea5efa8f66bc089bf","7bc1948556c54bd9877bd19df3c42de0","a3fd91ca54644b558b8f8eaf6e383775","98a8fa27a4584ab1bcb7ffd397c83306","eaeaccbb7d054d7597da1caafa96dc28","0c3a22962bef4bbf8b371ee39ce143bd","0aa4340426484012a63f9d8529a17c2c","2145d9e743e44b57b4545632fa4cb3ab","25cd8bdf3d3e4a26be08b5d2edfc7dd4","4696c64d93724f27bfe30613d6b73d16","aac6a57a0d7145ec9304dfbf180eeb27","add72d89c34546dca095d87e392d45e2","2d0b7c80a208489ebc44def1e00b86be","43eaa4c72419400fa8edd21e2ba61953","f2971f1535364672b1dfb6119c408e6b","f5e56e41edf44f79910cbd2dfb64acc6","6df90d4c42314c74bc3691f4e558d870","48444f89dc8d4a9784e847e9a9be42c6"]},"id":"mQOfoGgp1ByH","executionInfo":{"status":"ok","timestamp":1621808797711,"user_tz":-120,"elapsed":165510,"user":{"displayName":"Roman Engeler","photoUrl":"","userId":"01825020783678319162"}},"outputId":"d2bf21ae-803d-4b49-955c-3eeb90631cb6"},"source":["## Re-evaluate performance of model\n","\n","# load XLSR model\n","if not 'XLSRmodel' in globals():\n","  print('Load model')\n","  XLSRmodel = Wav2Vec2ForCTC.from_pretrained('./drive/MyDrive/Colab Notebooks/model/'+str(model_name)).to(\"cuda\")\n","  XLSRmodel2 = Wav2Vec2ForCTC.from_pretrained('./drive/MyDrive/Colab Notebooks/model/'+'checkpoint-8000').to(\"cuda\")\n","  XLSRmodel3 = Wav2Vec2ForCTC.from_pretrained('./drive/MyDrive/Colab Notebooks/model/wav2vec2-large-xlsr-french-01May/parameter-sweep-lr02-05-2021 08:06/checkpoint-2600').to(\"cuda\")\n","  XLSRmodel4 = Wav2Vec2ForCTC.from_pretrained('./drive/MyDrive/Colab Notebooks/model/wav2vec2-large-xlsr-french-23May/23-05-2021 18:11/checkpoint-4480').to(\"cuda\")\n","  XLSRmodel5 = Wav2Vec2ForCTC.from_pretrained('./drive/MyDrive/Colab Notebooks/model/wav2vec2-large-xlsr-french-01May/parameter-sweep-lr02-05-2021 14:09/checkpoint-2600').to(\"cuda\")\n","\n","# load processor\n","if not 'processor' in globals():\n","  print('Load processor')\n","  tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(\"facebook/wav2vec2-large-xlsr-53-french\")\n","  feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)\n","  processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)\n","\n","# prepare dataset\n","def prepare_dataset(batch):\n","    return processor(batch, return_tensors=\"pt\", sampling_rate=16*1e3)\n","\n","# word error rate\n","wer_metric = load_metric(\"wer\")\n","wer_ = []\n","\n","# entropy\n","softmax = nn.Softmax(dim=2)\n","entropy_ = []\n","\n","#\n","input_dict = df_valid['audio_signal'].apply(prepare_dataset)\n","\n","# WER over everything (one long string)\n","label_str = ''\n","pred_str = ''\n","\n","for idx in range(len(df_valid)):\n","  #print('-----------------')\n","  logits = XLSRmodel(input_dict.values[idx].input_values.to(\"cuda\")).logits\n","\n","  pred_ids = torch.argmax(logits, dim=-1)[0]\n","\n","  # WER over everything (one long string)\n","  pred_str+= processor.decode(pred_ids)+ ' '\n","  label_str+= df_valid[\"transcription\"].values[idx].lower()+ ' '\n","\n","  # entropy\n","  entropy_.append(np.mean(entropy(softmax(logits).detach().to(\"cpu\")[0].numpy())))\n","\n","wer_.append(wer_metric.compute(predictions=[pred_str], references=[label_str]))\n","\n","print(np.mean(wer_))\n","print(np.mean(entropy_))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Load model\n","Load processor\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a65eb6ddda9f4b66a101d3b341606c74","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=460.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b9401e00cde1488183b45fb2d4a97421","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=378.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a3fd91ca54644b558b8f8eaf6e383775","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=85.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aac6a57a0d7145ec9304dfbf180eeb27","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1947.0, style=ProgressStyle(description…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","0.0635106632294352\n","1.7888469\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OgboLRG43Hpp"},"source":["### Beam Search"]},{"cell_type":"code","metadata":{"id":"Oh7Hwn5g3AEx","executionInfo":{"status":"ok","timestamp":1621808803299,"user_tz":-120,"elapsed":655,"user":{"displayName":"Roman Engeler","photoUrl":"","userId":"01825020783678319162"}}},"source":["# Beam Search\n","# https://towardsdatascience.com/boosting-your-sequence-generation-performance-with-beam-search-language-model-decoding-74ee64de435a\n","def beam_search_decoder(predictions, top_k = 3):\n","    #start with an empty sequence with zero score\n","    output_sequences = [([], 0)]\n","    \n","    #looping through all the predictions\n","    for token_probs in predictions:\n","        new_sequences = []\n","        \n","        #append new tokens to old sequences and re-score\n","        for old_seq, old_score in output_sequences:\n","            for char_index in range(len(token_probs)):\n","                new_seq = old_seq + [char_index]\n","                #considering log-likelihood for scoring\n","                new_score = old_score + math.log(token_probs[char_index])\n","                new_sequences.append((new_seq, new_score))\n","                \n","        #sort all new sequences in the de-creasing order of their score\n","        output_sequences = sorted(new_sequences, key = lambda val: val[1], reverse = True)\n","        \n","        #select top-k based on score \n","        # *Note- best sequence is with the highest score\n","        output_sequences = output_sequences[:top_k]\n","        \n","    return output_sequences"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"80Mhxc6wpAW-","executionInfo":{"status":"ok","timestamp":1621808806847,"user_tz":-120,"elapsed":736,"user":{"displayName":"Roman Engeler","photoUrl":"","userId":"01825020783678319162"}},"outputId":"78cf3e2c-f6d6-4f35-cc1e-6e7cb5c741ab"},"source":["## Test beam search \n","idx = 10\n","nbeams = 10\n","softmax = nn.Softmax(dim=2)\n","\n","#\n","pred = []\n","input_dict = df_train['audio_signal'][idx:idx+1].apply(prepare_dataset)\n","\n","for idx in range(len(input_dict)):\n","  #print('-----------------')\n","  logits = XLSRmodel(input_dict.values[idx].input_values.to(\"cuda\")).logits\n","  # sum_j(output_ij) = 1 where i is column and j is row\n","  output = softmax(logits) # logits -> probabilities\n","\n","  beams_int = beam_search_decoder(torch.squeeze(output).tolist(), top_k = nbeams) # beams\n","  beams_str = nbeams*['']\n","\n","  for k in range(nbeams):\n","    pred_ids, pred_prob = beams_int[k]\n","    print(processor.decode(pred_ids))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["ban car mooy jaar\n","ban car mooy jaar\n","ban car mooy jaar\n","ban car mooy jaar\n","ban car mooy jaar\n","ban car mooy jaar\n","ban car mooy jaar\n","ban car mooy jaar\n","ban car mooy jaar\n","ban car mooy jaar\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"I3F24ZyA3LQ9"},"source":["### Word Level Language Model"]},{"cell_type":"code","metadata":{"id":"NZ2OOznq3AC7","executionInfo":{"status":"ok","timestamp":1621683302115,"user_tz":-120,"elapsed":1184,"user":{"displayName":"Roman Engeler","photoUrl":"","userId":"01825020783678319162"}}},"source":["## Language Model (n-gram vs KenLM)\n","# https://surfertas.github.io/deeplearning/pytorch/2017/08/20/n-gram.html # pytorch code (NN parametrization of LM)\n","# https://web.stanford.edu/~jurafsky/slp3/slides/LM_4.pdf\n","# https://www.kaggle.com/alvations/n-gram-language-model-with-nltk # code taken from here\n","# https://web.stanford.edu/~jurafsky/slp3/old_oct19/3.pdf -> improvements to LM's"],"execution_count":319,"outputs":[]},{"cell_type":"code","metadata":{"id":"uhXsAzIWQ6S-","executionInfo":{"status":"ok","timestamp":1621808812869,"user_tz":-120,"elapsed":654,"user":{"displayName":"Roman Engeler","photoUrl":"","userId":"01825020783678319162"}}},"source":["## Fitting of n-gram LM\n","def train_ngram(LMmodel, data):\n","  '''\n","  input: model, list of sentences\n","  output: trained model\n","  '''\n","  #\n","  sentence_list = [sentence for sentence in data]\n","\n","  # lower casing\n","  word_list_lower = [list(filter(None, [re.sub('[,().?!~;1234567890^]', '', word.lower()) for word in sentence.split(' ')])) for sentence in sentence_list]\n","\n","  # preprocess for language model\n","  train_data, padded_words = padded_everygram_pipeline(3, word_list_lower)\n","  \n","  # fit model\n","  LMmodel.fit(train_data, padded_words)\n","\n","  return LMmodel"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z4x8hRidS_nG","executionInfo":{"status":"ok","timestamp":1621808826892,"user_tz":-120,"elapsed":1794,"user":{"displayName":"Roman Engeler","photoUrl":"","userId":"01825020783678319162"}}},"source":["## Get perplexity of sentence\n","def ngram_logprobability(sentence):\n","    log_prob = 0\n","    count = 0\n","    for ngram in sentence:\n","      # there is probably an error in the implementation of KneserNeyInterpolated -> revert to MLE\n","      '''try:\n","        log_prob += np.log(LMKmodel.score(ngram[2], [ngram[0], ngram[1]]))\n","      except:\n","      '''\n","      # to avoid log(0) for unknown chars => many methods exist in the literature such as smoothing\n","      log_prob += np.log(LMmodel.score(ngram[2], [ngram[0], ngram[1]])+ 1e-8)\n","      count += 1\n","    return np.power(np.exp(log_prob), 1/count) # (inverse) perplexity to account for different word/ sentence length"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"72-oKWPoTESq","executionInfo":{"status":"ok","timestamp":1621808830665,"user_tz":-120,"elapsed":777,"user":{"displayName":"Roman Engeler","photoUrl":"","userId":"01825020783678319162"}}},"source":["## Get perplexity of list of sentences\n","def prob_sentences(sentences):\n","  '''\n","  input: list of sentences\n","  output: log probability for sentences\n","  '''\n","\n","  # list with log probabilities\n","  log_probs = len(sentences)* [-np.infty]\n","\n","  # creating list of sentences from string\n","  list_sentences = [sentence.split(' ') for sentence in sentences]\n","\n","  # lower casing\n","  for k in range(len(list_sentences)):\n","    list_sentences[k] = [word.lower() for word in list_sentences[k]]\n","\n","  # list(sentence_list(word_list(ngrams)))\n","  list_ngrams = [list(ngrams(pad_both_ends(sentence, n=3), n=3)) for sentence in list_sentences]\n","\n","  for k, sentence in enumerate(list_ngrams):\n","    log_probs[k] = ngram_logprobability(sentence)\n","\n","  return log_probs"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"BRCL1XtBPMXd"},"source":["## language model\n","LMKmodel = KneserNeyInterpolated(3) # Lets train a n-gram model KneserNeyInterpolated(n)\n","LMKmodel = train_ngram(LMKmodel, df_train['transcription'].values)\n","\n","# since there seems to be an error in the implementation of KneyerNey leading to errors -> fallback to standard MLE\n","LMmodel = MLE(3) # Lets train a n-gram model KneserNeyInterpolated(n)\n","LMmodel = train_ngram(LMmodel, df_train['transcription'].values)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kEDJRXzaQ7L3"},"source":["### Character Level Language Model"]},{"cell_type":"code","metadata":{"id":"cD79x0G12__v"},"source":["## fitting of language model\n","def train_ngram(LMmodel, data):\n","  '''\n","  input: model, list of sentences\n","  output: trained model\n","  '''\n","\n","  # one long string of words\n","  word_string = ' '.join(data)\n","\n","  # one long list of words\n","  word_list = word_string.split(' ')\n","\n","  # lower casing\n","  word_list_lower = [list(map(str.lower, [word]))[0]\n","                     for word in word_list]\n","\n","  # preprocess for language model\n","  train_data, padded_words = padded_everygram_pipeline(2, word_list_lower)\n","  \n","  # fit model\n","  LMmodel.fit(train_data, padded_words)\n","\n","  return LMmodel"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"id":"YI3YS3j72_9O","executionInfo":{"elapsed":2450,"status":"ok","timestamp":1619259100531,"user":{"displayName":"Roman Engeler","photoUrl":"","userId":"01825020783678319162"},"user_tz":-120},"outputId":"75cc9dbd-44fd-4ae4-a7a1-9b7ca18cca7b"},"source":["## language model\n","# IMPORTANT there seems to be a missmatch in the vocabulary (44 vs 49 chars)\n","# -> could lead to language model not knowing the character\n","LMmodel = MLE(3) # Lets train a n-gram model\n","LMmodel = train_ngram(LMmodel, df_train['transcription'].values)\n","print(LMmodel.vocab)\n","print(len(tokenizer.get_vocab()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<Vocabulary with cutoff=1 unk_label='<UNK>' and 776 items>\n","49\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nprint(LMmodel.counts['c'])\\nprint(LMmodel.counts[['c']]['o'])  # P('o'|'c')\\nprint(LMmodel.score('o', ['c']))\\nprint(LMmodel.vocab.lookup([char for char in test_lower[5]]))\\n\""]},"metadata":{"tags":[]},"execution_count":107}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r06wXfQlqmEV","executionInfo":{"elapsed":1306,"status":"ok","timestamp":1619259101340,"user":{"displayName":"Roman Engeler","photoUrl":"","userId":"01825020783678319162"},"user_tz":-120},"outputId":"995e24c1-645e-4a20-f4de-3d6e71999fcd"},"source":["# voabulary of language model (extracted from data)\n","print([ch for ch in LMmodel.vocab])\n","print(\"VERY STRANGE THAT THERE IS A c-cedi IN THE VOCABULARY EXTRACTED FROM THE TRAIN DATASET\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['<s>', 'rufsac', '</s>', 'pharmacie', 'talibou', 'dabo', 'avenue', 'faidherbe', 'cité', 'mére', 'thérésa', 'gare', 'de', 'thiaroye', 'rue', 'baffa', 'séne', 'double', 'less', 'grande', 'mosquée', 'derkle', 'thokho', 'tournalou', 'yeumbeul', 'marché', 'laa', 'bëgg', 'dem', 'sonadis', 'rufisque', 'sococim', 'depot', 'layousse', 'faouzy', 'grand', 'dakar', 'fann', 'hock', 'canada', 'taly', 'bu', 'makk', 'pont', 'colobane', 'garage', 'camion', 'vidange', 'hopital', 'jean', 'la', 'fontaine', 'mariste', 'lamine', 'gueye', 'croisement', 'keur', 'massar', 'essence', 'touré', 'comico', 'darou', 'salam', 'parc', 'forestier', 'hann', 'massalikoul', 'jinan', 'ecobank', 'des', 'far', 'dama', 'mame', 'sira', 'ban', 'oto', 'mooy', 'jaar', 'yoff', 'yarakh', 'malicka', 'champ', 'course', 'pikine', 'seydina', 'limamoulaye', 'edk', 'oil', 'ali', 'baba', 'rond', 'point', 'mbao', 'diaxay', 'lycée', 'thierno', 'seydou', 'nourou', 'tall', 'petit', 'extension', 'bountou', 'ecole', 'les', 'pédagogues', 'police', 'parcelles', 'assainies', 'car', 'bank', 'of', 'africa', 'nan', 'laay', 'def', 'ngir', 'boulangerie', 'jaune', 'mamelles', 'tivaoune', 'peulh', 'fadia', 'orabank', 'sagef', 'elimanel', 'fall', 'thiakhogne', 'mermoz', 'dékh', 'fleuve', 'diacksao', 'terrain', 'nation', 'unies', 'zone', 'b', 'hlm', 'ndiaréme', 'thiossane', 'dieupeul', 'elhadji', 'mansour', 'sy', 'bus', 'danguou', 'lpa', 'asecna', 'ouakam', 'ferroviaire', 'station', 'shell', 'cambérène', 'port', 'sandiniery', 'echangeur', 'routiére', 'beaux', 'maraichiers', 'elton', 'ouest', 'foire', 'clinique', 'du', 'cap', 'manuel', 'gendarmerie', 'diall', \"m'baye\", 'camp', 'sékou', 'mballo', 'terminus', 'frigo', 'niary', 'tally', 'stade', 'seffa', 'ada', 'seck', 'centre', 'electrique', 'kounoune', 'tigo', 'almadies', 'embarcadére', 'gorée', 'sipres', 'al', 'azhar', 'sips', 'cimetiere', 'bétoir', 'niaye', 'khar', 'yalla', 'p', 'a', 'i', 'cimetiére', 'musulmane', 'route', 'hydrocarbures', 'lobat', 'mairie', 'lycee', 'blaise', 'diagne', 'nave', 'poste', 'courant', 'xarit', 'couture', 'sicap', 'baobab', 'niague', 'amadou', 'barry', 'bousso', 'dramé', 'notaire', 'total', 'médina', 'gounass', 'ba', 'bou', 'bess', 'cfao', 'motors', 'senegal', 'diaxxay', 'eaux', 'diockoul', 'just', 'for', 'u', 'sud', 'passage', 'icotaf', 'boulevard', 'gueule', 'tapée', 'hance', 'bernard', 'sde', 'axa', 'assurance', 'place', \"l'independance\", 'gouy', 'gui', 'diakayy', 'sonatel', 'zac', 'ics', 'béss', 'transfusion', 'sanguine', 'central', 'zinc', 'soboa', 'avion', 'cheikh', 'ahmadou', 'bamba', 'mbacke', 'souvenir', 'africain', 'feu', 'rouge', 'brioche', 'dorée', 'diamalaye', 'ville', 'sedami', 'nord', 'serigne', \"m'backé\", 'maternité', 'ndiarème', 'limamou', 'laye', 'tacko', 'ngor', 'cite', 'groupe', 'honda', 'ndaw', 'rts', 'las', 'palmas', 'le', 'baol', 'cyrnos', 'zoologique', 'rail', 'bi', 'fass', 'guediawaye', 'cem', 'joseph', 'felix', 'corréa', 'camberéne', \"d'akor\", 'assemblée', 'dieu', 'baobabs-', 'temple', 'nations', 'elementaire', 'iba', 'tali', 'bargny', 'khourounar', 'usine', 'méche', 'darling', 'dalal', 'diam', 'nganladou', 'diouf', 'mbeubeuss', 'diallo', 'tournal', 'assane', 'capec', 'niakoul', 'rap', 'nandos', 'baye', 'niasse', 'abass', 'ndao', 'benn', 'barack', 'menuserie', 'ebéniste', 'lamp', 'diop', 'nationale', 'dioutiba', 'sacré', 'coeur', 'elisabeth', 'l’indépendance', 'castor', 'bel', '-', 'air', 'routière', 'pompier', 'oilibya', 'peytavin', 'douane', 'golf', 'océan', 'guédiawaye', 'eric', 'kayser', 'front', 'terre', 'dior', 'radio', 'futurs', 'media', 'rfm', 'coisement', 'cimetière', 'universite', 'hampate', 'supdeco', 'campus', 'e', 'mbedou', 'académia', 'sapeur', \"l'obelisque\", 'ndunkou', 'mbaye', 'yengoulene', 'castors', 'anta', 'marie', 'sarr', 'arret', 'patte', \"d'oie\", 'boune', 'tapé', 'alassane', 'djigo', 'alioune', 'sow', 'thioub', 'biagui', 'chambre', 'commerce', 'orca', 'escoa', 'pompiers', 'universitaire', 'soumbédioune', 'collège', 'cœur', 'mamadou', 'kakatar', 'par', 'dupont', 'et', 'demba', 'bceao', 'samu', 'municipale', 'grand-yoff', 'basket', 'principal', 'technopole', 'marchée', 'tandem', 'immobilier', 'scat', 'urbam', 'bissap', 'routiere', 'case', 'philipe', 'maguiléne', 'senghor', '', 'x', 'virage', 'lac', 'rose', 'ndiaye', 'enseignent', 'doudou', 'basse', 'agence', 'immo', 'mbengue', 'sovonel', 'sandaga', 'roi', 'baudouin', 'ponty', 'djily', 'baobabs', 'medina', 'etoile', 'albert', 'sarraut', 'nu', 'may', 'assemblee', 'palais', 'presidentiel', 'femme', 'auto', 'santhiaba', 'pressafrik', 'cafétéria', 'creations', 'yavuz', 'sélim', 'bosphore', \"l'emergence\", 'mbédou', 'lébous', 'mbénguéne', 'carrapide', 'dépot', 'dikk', 'sapeurs', 'bachir', 'saint', 'pierre', 'fks', 'farine', 'western', 'union', 'cinéma', 'pasteur', 'dial', 'bass', 'dalifort', 'bd', 'général', 'gaule', 'centenaire', 'mouride', 'el', 'hadji', 'ibrahima', 'pénitence', 'daroukhane', 'bonnet', 'autoroute', 'seydina-limamoulaye', 'diarra', 'marechal', 'ndox', 'yaye', 'allées', 'cheikhna', 'sidaty', 'aîdara', 'penitence', 'justice', 'tableau', 'ferrailes', 'théâtre', 'national', 'malika', 'mangazin', 'jardin', 'botanique', 'primaire', 'bén', 'camberene', 'niass', 'malick', 'ancien', 'lgi', 'bem', 'aeroport', 'ministère', 'santé', 'prévention', 'aéroport', 'buiscuterie', 'kappa', 'galandou', 'supermarché', 'machallah', 'maristes', 'mar', 'enseignant', 'daral', 'ndax', 'mën', 'naa', 'jël', 'zola', 'cours', 'sainte', 'wade', 'martyr', \"l'ouganda\", 'derklé', 'penitance', 'emg', 'automobile', 'téne', 'parfumerie', 'gandour', 'village', 'art', 'sahm', 'poisson', 'biches', 'guigon', 'saveurs', \"d'asie\", 'sherif', 'ouseynou', 'thiaw', 'orange', 'face', 'contenaire', 'district', 'sanitaire', 'est', 'sauvegarde', 'hôpital', 'cto', 'feroviére', 'issa', 'cambéréne', 'scolaire', 'gaston', 'berger', 'grands', 'moulins', 'université', 'virtuel', 'sénégal', 'sultan', 'prefecture', 'lo', 'bira', 'complexe', 'xelcom', 'bache', 'ly-mo-dac', 'casino', 'vert', 'senelec', 'fan', 'jële', 'sedima', 'restaurant', 'venisia', 'parcelle', 'marchande', 'saf', 'bar', 'batrain', 'fi', 'sportiff', 'pamecas', 'cms', 'clando', 'daniel', 'sorano', 'hospitalier', 'aristide', 'dantec', 'difoncé', 'militaire', 'comercial', 'plateau', 'dialoré', 'plage', 'liberté', 'socio', 'culturel', 'wakhinane', 'nimzatt', 'claudel', \"d'epuration\", 'douta', 'baraka', 'oncf', 'demeure', 'caesar', 'stadium', 'marius', 'notre', 'dame', 'fastef', 'commissariat', 'dieuppeul', 'vdn', 'péage', 'mbenguéne', 'guinaw', 'rails', 'kennedy', 'kaki', 'institution', 'immaculée', 'conception', 'karack', 'ndiakhirate', 'sandicat', 'nabil', 'choucair', 'imprimerie', 'tandjan', 'sgbs', 'hotel', 'terrou', 'canal', 'dagoudane', 'ndoyéne', 'lébou', 'béthio', 'acapes', 'mbor', 'rouidate', 'thiane', 'ngogne', 'birane', 'ly', 'cosmetique', 'fallou', 'papa', 'guèye', 'tiléne', 'texaco', 'petersen', 'sodida', 'ndeureuhlou', 'club', 'ministre', 'khonkh', 'clean', 'fahd', 'ben', 'abdel', 'aziz', 'normale', 'supérieure', 'ningala', 'adji', 'niagna', 'dispensaire', 'norade', 'diamaguéne', 'maurice', 'delafosse', 'dominique', 'ministere', \"l'interieur\", 'senegalais', 'youssou', 'mbargane', 'ravin', 'sica', 'thiakhane', 'lat', 'flag', 'diarri', 'poul', 'medine', 'lazzare', 'privée', 'petits', 'génies', 'christa', 'talli', 'mourade', 'mbacké', 'mamelle', 'jet', \"d'eau\", 'awa', 'sante', 'gaspar', 'camara', 'cices', 'magic', 'land', \"l'obélisque\", 'saldia', 'mosquee', 'mbeur', 'abiya', 'kenedy', 'fu', 'mu', 'jëm', 'abebe', 'bikila', 'sengor', 'sofrac', 'pour', 'rokhaya', 'attijari', 'izdihar', 'bourguiba', 'poind', 'africatel', 'avs', 'diaakay', 'fouta', 'hôtel', 'diouma', 'leclerc', 'sotiba', 'hyacinthe', 'thiandoum', 'safco', 'caserne', 'samba', 'diéri', 'français', 'intersection', 'raby', 'equipe', 'plus', 'sur', 'mer', 'nioul', 'cge', '<UNK>']\n","VERY STRANGE THAT THERE IS A c-cedi IN THE VOCABULARY EXTRACTED FROM THE TRAIN DATASET\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g1_X0PHppglm","executionInfo":{"elapsed":1117,"status":"ok","timestamp":1619259101340,"user":{"displayName":"Roman Engeler","photoUrl":"","userId":"01825020783678319162"},"user_tz":-120},"outputId":"806a24da-d34c-4638-cc51-a1d89e071847"},"source":["# vocabulary used by tokenizer (french alphabet)\n","vocab_dict = {v for k, v in enumerate(tokenizer.get_vocab())}\n","vocab_tokenizer = [v.lower() for v in vocab_dict]\n","print(vocab_tokenizer)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['m', \"'\", 'ë', 'r', 'v', 'ô', 'k', '<pad>', 'l', 'æ', 's', 'e', 'û', 'u', 'f', 'c', 'o', 'a', 'i', 'b', 'ù', 'â', 'ç', 'œ', 'w', 'd', 'ü', 'n', 'y', 't', 'î', 'q', '-', 'é', 'ï', 'è', 'j', '</s>', 'à', 'h', 'p', 'ê', '<s>', 'ÿ', 'g', 'z', 'x', '|', '<unk>']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GJIQfTGZ2_6w"},"source":["## Perplexity\n","def ngram_logprobability(sentence):\n","    log_prob = 0\n","    count = 0\n","    for words in sentence:\n","      for ngram in words:\n","        # to avoid log(0) for unknown chars => many methods exist in the literature such as smoothing\n","        # since log is monotonically increasing, adding a const should not change the ordering, right?\n","        log_prob += np.log(LMmodel.score(ngram[1], [ngram[0]])+ 1e-8)\n","        count += 1\n","    return np.power(np.exp(log_prob), 1/count) # (inverse) perplexity to account for different word/ sentence length"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R_tgrLoB2_31"},"source":["## Probability of sentence\n","def prob_sentences(sentences):\n","  '''\n","  input: list of sentences\n","  output: log probability for sentences\n","  '''\n","  # list with log probabilities\n","  log_probs = len(sentences)* [-np.infty]\n","\n","  # creating list of sentences from string\n","  list_sentences = [sentence.split(' ') for sentence in sentences]\n","\n","  # lower casing\n","  for k in range(len(list_sentences)):\n","    list_sentences[k] = [list(map(str.lower, [sent]))[0]\n","                        for sent in list_sentences[k]]\n","\n","  # list(sentence_list(word_list(ngrams)))\n","  list_ngrams = [[list(ngrams(pad_both_ends(word, n=2), n=2)) for word in sentence] for sentence in list_sentences]\n","\n","  for k, sentence in enumerate(list_ngrams):\n","    log_probs[k] = ngram_logprobability(sentence)\n","\n","  return log_probs"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DzW0gVN_TIjq"},"source":["### Validation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kXy3g_7qrScm","executionInfo":{"status":"ok","timestamp":1621805757800,"user_tz":-120,"elapsed":1052056,"user":{"displayName":"Roman Engeler","photoUrl":"","userId":"01825020783678319162"}},"outputId":"a6e8f9a5-892c-4197-d0aa-7b796653173a"},"source":["## Predictions\n","nbeams = 20 # this should scale roughly linearly to runtime -> with 10 runs for about 10 mins\n","alpha = 0.\n","cutoff = 0.5\n","\n","# pre-processing of data\n","input_dict = df_valid['audio_signal'].apply(prepare_dataset)\n","\n","# word error rate\n","wer_ = []\n","\n","#\n","softmax = nn.Softmax(dim=2)\n","\n","# strings to calculate wer\n","label_str = ''\n","pred_str = ''\n","\n","# loop through validation set\n","for idx in range(len(df_valid)):\n","  #print('-----------------')\n","  ## Model 1\n","  logits = XLSRmodel(input_dict.values[idx].input_values.to(\"cuda\")).logits\n","  # sum_j(output_ij) = 1 where i is column and j is row\n","  output = softmax(logits) # logits -> probabilities\n","\n","  # beam search\n","  beams_int = beam_search_decoder(torch.squeeze(output).tolist(), top_k = nbeams) # beams\n","  beams_str = 3*nbeams*['']\n","  beams_XLSR_prob = 3*nbeams*[0]\n","\n","  for k in range(nbeams):\n","    pred_ids, pred_prob = beams_int[k]\n","    beams_XLSR_prob[k] = np.exp(pred_prob)\n","    beams_str[k] = processor.decode(pred_ids)\n","\n","  ## Model 2\n","  logits = XLSRmodel2(input_dict.values[idx].input_values.to(\"cuda\")).logits\n","  output = softmax(logits) # logits -> probabilities\n","\n","  # beam search\n","  beams_int = beam_search_decoder(torch.squeeze(output).tolist(), top_k = nbeams) # beams\n","\n","  for k in range(nbeams):\n","    pred_ids, pred_prob = beams_int[k]\n","    beams_XLSR_prob[nbeams+ k] = np.exp(pred_prob)\n","    beams_str[nbeams+ k] = processor.decode(pred_ids)\n","\n","  ## Model 3\n","  logits = XLSRmodel3(input_dict.values[idx].input_values.to(\"cuda\")).logits\n","  output = softmax(logits) # logits -> probabilities\n","\n","  # beam search\n","  beams_int = beam_search_decoder(torch.squeeze(output).tolist(), top_k = nbeams) # beams\n","\n","  for k in range(nbeams):\n","    pred_ids, pred_prob = beams_int[k]\n","    beams_XLSR_prob[2*nbeams+ k] = np.exp(pred_prob)\n","    beams_str[2*nbeams+ k] = processor.decode(pred_ids)\n","\n","  if idx% 100 == 0:\n","    print(idx)\n","\n","  # append prediction\n","  #pred_str+= ' '.join(pred).replace('<unk>', '')+ ' '\n","  beams_LM_prob = prob_sentences(beams_str)\n","  pred_ = beams_str[np.argmax([pLM+alpha*pXLSR for pLM, pXLSR in zip(beams_LM_prob, beams_XLSR_prob)])].replace('<unk>', '')\n","\n","  # nearest neighbor\n","  pred = []\n","  for word in pred_.split(' '):\n","    sim = difflib.get_close_matches(word, xv, n=1)\n","\n","    if sim == []:\n","      sim = word\n","    else:\n","      sim = sim[0]\n","\n","    pred.append(sim)\n","  \n","  # append to prediction\n","  pred_str += ' '.join(pred)+ ' '\n","\n","  #pred_str+= pred_+ ' '\n","  label_str+= df_valid[\"transcription\"].values[idx].lower()+ ' '\n","  \n","# calculate wer\n","wer_.append(wer_metric.compute(predictions=[pred_str], references=[label_str]))\n","\n","print(np.mean(wer_))"],"execution_count":114,"outputs":[{"output_type":"stream","text":["0\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","0.016639325052730254\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FtWwOM_31G1E"},"source":["### Prediction"]},{"cell_type":"code","metadata":{"id":"4cAyWHup1IGk","executionInfo":{"status":"ok","timestamp":1621808855409,"user_tz":-120,"elapsed":4939,"user":{"displayName":"Roman Engeler","photoUrl":"","userId":"01825020783678319162"}}},"source":["## prediction\n","# load data (dataframe) -> empty entries\n","df_test = pd.read_feather('drive/MyDrive/Colab Notebooks/data/ASR_test_audio1564.ft')\n","df_test = df_test[['ID', 'audio_signal']]\n","df_test.head()\n","\n","def prepare_dataset(batch):\n","    return processor(batch, return_tensors=\"pt\", sampling_rate=16*1e3)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h4tNbrEyNLnJ","executionInfo":{"status":"ok","timestamp":1621810917990,"user_tz":-120,"elapsed":1890110,"user":{"displayName":"Roman Engeler","photoUrl":"","userId":"01825020783678319162"}},"outputId":"3f351921-555b-497c-cddf-04ddb728bd13"},"source":["# run through pre-processor\n","input_dict = df_test['audio_signal'].apply(prepare_dataset)\n","\n","# to store predictions\n","preds = []\n","\n","# beams\n","nbeams = 20\n","alpha = 0.\n","\n","#\n","softmax = nn.Softmax(dim=2)\n","\n","# run through model and decoder\n","for idx in range(len(df_test)):\n","  ## Model 1\n","  logits = XLSRmodel(input_dict.values[idx].input_values.to(\"cuda\")).logits\n","  # sum_j(output_ij) = 1 where i is column and j is row\n","  output = softmax(logits) # logits -> probabilities\n","\n","  # beam search\n","  beams_int = beam_search_decoder(torch.squeeze(output).tolist(), top_k = nbeams) # beams\n","  beams_str = 5*nbeams*['']\n","  beams_XLSR_prob = 5*nbeams*[0]\n","\n","  for k in range(nbeams):\n","    pred_ids, pred_prob = beams_int[k]\n","    beams_XLSR_prob[k] = np.exp(pred_prob)\n","    beams_str[k] = processor.decode(pred_ids)\n","\n","  ## Model 2\n","  logits = XLSRmodel2(input_dict.values[idx].input_values.to(\"cuda\")).logits\n","  # sum_j(output_ij) = 1 where i is column and j is row\n","  output = softmax(logits) # logits -> probabilities\n","\n","  # beam search\n","  beams_int = beam_search_decoder(torch.squeeze(output).tolist(), top_k = nbeams) # beams\n","\n","  for k in range(nbeams):\n","    pred_ids, pred_prob = beams_int[k]\n","    beams_XLSR_prob[nbeams+ k] = np.exp(pred_prob)\n","    beams_str[nbeams+ k] = processor.decode(pred_ids)\n","\n","  ## Model 3\n","  logits = XLSRmodel3(input_dict.values[idx].input_values.to(\"cuda\")).logits\n","  # sum_j(output_ij) = 1 where i is column and j is row\n","  output = softmax(logits) # logits -> probabilities\n","\n","  # beam search\n","  beams_int = beam_search_decoder(torch.squeeze(output).tolist(), top_k = nbeams) # beams\n","\n","  for k in range(nbeams):\n","    pred_ids, pred_prob = beams_int[k]\n","    beams_XLSR_prob[2*nbeams+ k] = np.exp(pred_prob)\n","    beams_str[2*nbeams+ k] = processor.decode(pred_ids)\n","\n","  ## Model 4\n","  logits = XLSRmodel4(input_dict.values[idx].input_values.to(\"cuda\")).logits\n","  # sum_j(output_ij) = 1 where i is column and j is row\n","  output = softmax(logits) # logits -> probabilities\n","\n","  # beam search\n","  beams_int = beam_search_decoder(torch.squeeze(output).tolist(), top_k = nbeams) # beams\n","\n","  for k in range(nbeams):\n","    pred_ids, pred_prob = beams_int[k]\n","    beams_XLSR_prob[3*nbeams+ k] = np.exp(pred_prob)\n","    beams_str[3*nbeams+ k] = processor.decode(pred_ids)\n","\n","  ## Model 5\n","  logits = XLSRmodel5(input_dict.values[idx].input_values.to(\"cuda\")).logits\n","  # sum_j(output_ij) = 1 where i is column and j is row\n","  output = softmax(logits) # logits -> probabilities\n","\n","  # beam search\n","  beams_int = beam_search_decoder(torch.squeeze(output).tolist(), top_k = nbeams) # beams\n","\n","  for k in range(nbeams):\n","    pred_ids, pred_prob = beams_int[k]\n","    beams_XLSR_prob[4*nbeams+ k] = np.exp(pred_prob)\n","    beams_str[4*nbeams+ k] = processor.decode(pred_ids)\n","\n","  if idx% 100 == 0:\n","    print(idx)\n","\n","  # append prediction\n","  #pred_str+= ' '.join(pred).replace('<unk>', '')+ ' '\n","  beams_LM_prob = prob_sentences(beams_str)\n","  pred_str = beams_str[np.argmax([pLM+alpha*pXLSR for pLM, pXLSR in zip(beams_LM_prob, beams_XLSR_prob)])].replace('<unk>', '').replace('\"', '')\n","\n","  # nearest neighbor\n","  pred = []\n","  for word in pred_str.split(' '):\n","    sim = difflib.get_close_matches(word, xv, n=1)\n","\n","    if sim == []:\n","      sim = word\n","    else:\n","      sim = sim[0]\n","\n","    pred.append(sim)\n","  \n","  # append to prediction\n","  preds.append(' '.join(pred))\n","  #preds.append(pred_str)\n","\n","# save as csv\n","dfpred = pd.DataFrame(list(zip(list(df_test['ID'].values), preds)), columns=['ID', 'transcription'])\n","dfpred.to_csv('./drive/MyDrive/Colab Notebooks/'+str(save_name), index=False)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["0\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qLGTkE60R7yc"},"source":[""],"execution_count":null,"outputs":[]}]}